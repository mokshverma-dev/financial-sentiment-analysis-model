{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213524d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Financial Sentimental Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10423529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be06edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526f68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "\n",
    "k=KNeighborsClassifier()\n",
    "d=DecisionTreeClassifier()\n",
    "r=RandomForestClassifier()\n",
    "l=LogisticRegression()\n",
    "mb=MultinomialNB()\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "# from PIL import Image\n",
    "\n",
    "# from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d07773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cae59e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0     The GeoSolutions technology will leverage Bene...  positive\n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2     For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4     The Swedish buyout firm has sold its remaining...   neutral\n",
       "...                                                 ...       ...\n",
       "5837  RISING costs have forced packaging producer Hu...  negative\n",
       "5838  Nordic Walking was first used as a summer trai...   neutral\n",
       "5839  According shipping company Viking Line , the E...   neutral\n",
       "5840  In the building and home improvement trade , s...   neutral\n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
       "\n",
       "[5842 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4e68e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     object\n",
       "Sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'] = df['Sentiment'].astype(str)\n",
    "sentiment=[]\n",
    "for i in df['Sentiment']:\n",
    "    sentiment.append(i)\n",
    "   \n",
    "# print(sentiment)\n",
    "    \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5978cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model .\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Sentence\"][0])\n",
    "print(df['Sentiment'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2ac1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3130\n",
       "positive    1852\n",
       "negative     860\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f45d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"]=df[\"Sentence\"].str.lower() #We convert our texts to lowercase.\n",
    "df[\"Sentence\"]=df[\"Sentence\"].str.replace(\"[^\\w\\s]\",\"\") #We remove punctuation marks from our texts.\n",
    "df[\"Sentence\"]=df[\"Sentence\"].str.replace(\"\\d+\",\"\") #We are removing numbers from our texts.\n",
    "df[\"Sentence\"]=df[\"Sentence\"].str.replace(\"\\n\",\"\").replace(\"\\r\",\"\") #We remove spaces in our texts.\n",
    "df_neutral=df.loc[df['Sentiment']== 'neutral', 'Sentence']\n",
    "df_positive=df.loc[df['Sentiment']== 'positive', 'Sentence']\n",
    "df_negative=df.loc[df['Sentiment']== 'negative', 'Sentence']\n",
    "df[\"Sentiment\"]=df[\"Sentiment\"].map({'positive':1,'negative':0,'neutral':2})\n",
    "df['Sentiment']=df['Sentiment'].astype(float)\n",
    "df1=df[df['Sentiment']!=2]\n",
    "#We replace negative texts with 0 and positive texts with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e80eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer(lowercase=True,stop_words=\"english\")\n",
    "x=df1.Sentence\n",
    "y=df1.Sentiment\n",
    "x=vect.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eae225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classification_funct(x,y):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=60)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "    \n",
    "    k=KNeighborsClassifier()\n",
    "    d=DecisionTreeClassifier()\n",
    "    r=RandomForestClassifier()\n",
    "    l=LogisticRegression()\n",
    "    mb=MultinomialNB()\n",
    "    \n",
    "    algos=[k,d,r,l,mb]\n",
    "    algo_names=['KNeighborsClassifier','DecisionTreeClassifier','RandomForestClassifier','LogisticRegression','MultinomialNB']\n",
    "    \n",
    "    accuracy_scored=[]\n",
    "    precision_scored=[]\n",
    "    recall_scored=[]\n",
    "    f1_scored=[]\n",
    "    \n",
    "    for item in algos:\n",
    "        item.fit(x_train,y_train)\n",
    "        accuracy_scored.append(accuracy_score(y_test,item.predict(x_test)))\n",
    "        precision_scored.append(precision_score(y_test,item.predict(x_test)))\n",
    "        recall_scored.append(recall_score(y_test,item.predict(x_test)))\n",
    "        f1_scored.append(f1_score(y_test,item.predict(x_test)))\n",
    "        \n",
    "    result=pd.DataFrame(columns=['f1_score','recall_score','precision_score','accuracy_score'],index=algo_names)\n",
    "    result.f1_score=f1_scored\n",
    "    result.recall_score=recall_scored\n",
    "    result.precision_score=precision_scored\n",
    "    result.accuracy_score=accuracy_scored\n",
    "    sentiment_classification_funct.result=result.sort_values('f1_score',ascending=False)\n",
    "    return result.sort_values('f1_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9a9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2169, 6598) (543, 6598) (2169,) (543,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.881273</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.821363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.821596</td>\n",
       "      <td>0.812155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.872629</td>\n",
       "      <td>0.813996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.844673</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.816377</td>\n",
       "      <td>0.777164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.825359</td>\n",
       "      <td>0.917553</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.731123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        f1_score  recall_score  precision_score  \\\n",
       "RandomForestClassifier  0.881273      0.957447         0.816327   \n",
       "LogisticRegression      0.872818      0.930851         0.821596   \n",
       "MultinomialNB           0.864430      0.856383         0.872629   \n",
       "DecisionTreeClassifier  0.844673      0.875000         0.816377   \n",
       "KNeighborsClassifier    0.825359      0.917553         0.750000   \n",
       "\n",
       "                        accuracy_score  \n",
       "RandomForestClassifier        0.821363  \n",
       "LogisticRegression            0.812155  \n",
       "MultinomialNB                 0.813996  \n",
       "DecisionTreeClassifier        0.777164  \n",
       "KNeighborsClassifier          0.731123  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classification_funct(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61464e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc(data,bgcolor):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    mask=np.array(Image.open(\"Stock Market.png\"))\n",
    "    wc=WordCloud(background_color=bgcolor,stopwords=STOPWORDS,mask=mask)\n",
    "    wc.generate(\" \".join(data))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "#We draw the most used words in tweets on a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe759223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent=df[[\"Sentence\",\"Sentiment\"]]\n",
    "sent=pd.DataFrame({\"Sentence\":df['Sentence'], \"Sentiment\":df['Sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d2d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sentiment(Sentence):\n",
    "    return TextBlob(Sentence).sentiment.polarity\n",
    "#We are doing our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "295ea626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the geosolutions technology will leverage bene...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esi on lows down  to  bk a real possibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for the last quarter of   componenta s net sal...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>according to the finnishrussian chamber of com...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment  \\\n",
       "0  the geosolutions technology will leverage bene...        1.0   \n",
       "1        esi on lows down  to  bk a real possibility        0.0   \n",
       "2  for the last quarter of   componenta s net sal...        1.0   \n",
       "3  according to the finnishrussian chamber of com...        2.0   \n",
       "4  the swedish buyout firm has sold its remaining...        2.0   \n",
       "\n",
       "   sentiment_analysis  \n",
       "0            0.209091  \n",
       "1            0.022222  \n",
       "2            0.000000  \n",
       "3            0.062500  \n",
       "4           -0.100000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[\"sentiment_analysis\"]=sent[\"Sentence\"].apply(detect_sentiment)\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6b6f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment2(sent):\n",
    "    if (sent< -0.02):\n",
    "        return 3\n",
    "    elif sent>0.02:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#We divide the texts into three groups positive, negative and nÃ¶tr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7a92e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>Sentiment_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the geosolutions technology will leverage bene...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esi on lows down  to  bk a real possibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for the last quarter of   componenta s net sal...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>according to the finnishrussian chamber of com...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment  \\\n",
       "0  the geosolutions technology will leverage bene...        1.0   \n",
       "1        esi on lows down  to  bk a real possibility        0.0   \n",
       "2  for the last quarter of   componenta s net sal...        1.0   \n",
       "3  according to the finnishrussian chamber of com...        2.0   \n",
       "4  the swedish buyout firm has sold its remaining...        2.0   \n",
       "\n",
       "   sentiment_analysis  Sentiment_position  \n",
       "0            0.209091                   1  \n",
       "1            0.022222                   1  \n",
       "2            0.000000                   0  \n",
       "3            0.062500                   1  \n",
       "4           -0.100000                   3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[\"Sentiment_position\"]=sent[\"sentiment_analysis\"].apply(sentiment2)\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa90d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.000000    2983\n",
      " 0.100000     123\n",
      " 0.250000     111\n",
      " 0.136364     104\n",
      "-0.200000      98\n",
      "             ... \n",
      " 0.404167       1\n",
      " 0.155682       1\n",
      " 0.033333       1\n",
      "-0.005556       1\n",
      "-0.011905       1\n",
      "Name: sentiment_analysis, Length: 541, dtype: int64\n",
      "0    3048\n",
      "1    1773\n",
      "3    1021\n",
      "Name: Sentiment_position, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sent.sentiment_analysis.value_counts())\n",
    "print(sent.Sentiment_position.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
